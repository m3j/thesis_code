#collection of commands used in my thesis:
# if they have been run on qsub the filename will be present. otherwise it has been executed on iqsub. 

___________________________________________________________________________

###data download: qsub_chicken_data_download.sh
# data downloads from NCBI using SRA tools, converted to zipped fastq files.  

cd /home/projects/dtu_00009/data/chicken_data_TM;
prefetch --output-directory /home/projects/dtu_00009/data/chicken_data_TM --option-file run_ids;
fastq-dump --gzip --split-files *.sra;

___________________________________________________________________________

### subsampling without parallels on predefined fastsubset.list : qsub_data_subset.sh

while read f; do
  seqtk sample $f 10000 | gzip - -c > /home/projects/dtu_00009/data/chicken_data_TM/subset/$f 
done <fastq_subset.list
_____________________

## subsampling with GNU parallels

cd /home/projects/dtu_00009/data/chicken_data_TM 

#create a list with all fastq file names
ls | grep ‘.fastq.gz$’ > subset/fastq.list

# test with one sample:
# seqtk sample SRR9113737_1.fastq.gz 1000 | gzip - -c > /home/projects/dtu_00009/data/chicken_data_TM/subset/SRR9113737_1.fastq.gz 

# running in parallel 
parallel -j 38 "seqtk sample {} 10000 | gzip - -c > /home/projects/dtu_00009/data/chicken_data_TM/subset/{}" :::: fastq.list
_________________________________________________________________________

###Quality check: on iqsub with 1 node and 40 cores.  

# for test on subset: fastqc -o /fastQC -t 38 *.fastq.gz

cd /home/projects/dtu_00009/data/chicken_data_TM

#250MB pr thread
fastqc -o /fastQC/initial_QC -t 40 *.fastq.gz
fastqc -o ../fastQC -t 40 *.fastq.gz

conda activate env_python3.6
multiqc .
___________________________________________________________________________

## removing adapters and first 5 bases with bbmap and bbduk  
# qsub_bbmap.sh

parallel --xapply -j 4 "bbduk.sh ref=/home/projects/dtu_00009/data/chicken_data_TM/adapter.fa forcetrimleft=5 i
n1={1} in2={2} out1=Trimmed/{1} out2=Trimmed/{2} ktrim=r k=23 mink=11 hdist=1 hdist2=0 tpe tbo" :::: r1.list ::
:: r2.list


#2.omgang med parallels udenfor

parallel --xapply "qsub -F '{1} {2}' /home/projects/dtu_00009/data/Scripts/qsub_bbmap.sh " :::: /home/projects/dtu_00009/data/chicken_data_TM/r1.list :::: /home/projects/dtu_00009/data/chicken_data_TM/r2.list

___________________________________________________________________________

## removing low quality with sickle :
# qsub_sickle.sh 

ls Trimmed | grep '_1.fastq.gz$' > trimmed_r1.list
ls Trimmed | grep '_2.fastq.gz$' > trimmed_r2.list

#Running sickle on all samples to remove <50 bp reads and low quality sequences.
parallel --xapply -j 4 "sickle pe -t sanger -g -f Trimmed/{1} -r Trimmed/{2} -l 50 -o Hquality/{1} -p Hquality/
{2} -s Hquality/{1.}_singles.fastq.gz" :::: trimmed_r1.list :::: trimmed_r2.list

#2omgang m parallels udenfor
parallel --xapply "qsub -F '{1} {2}' /home/projects/dtu_00009/data/Scripts/qsub_sickle.sh " :::: /home/projects/dtu_00009/data/chicken_data_TM/trimmed_r1.list :::: /home/projects/dtu_00009/data/chicken_data_TM/trimmed_r2.list
___________________________________________________________________________

# removing PhiX contamination - running with parallels. - remember to specify threads

cd /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/Hquality

ls | grep 'fastq.gz' > reads.list

parallel -j 4 "bbduk.sh in={} out=../NoPhiX/{} ref=../phix174_ill.ref.fa k=31 hdist=1" :::: reads.list

# When running paralles outside the qsub-file but runing a different q_sub on each file. 
# qsub_Phix_removal.sh

# for the paired reads
parallel --xapply "qsub -F '{1} {2}' /home/projects/dtu_00009/data/Scripts/qsub_Phix_removal.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/HQ_read1.list :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/HQ_read2.list

#for the single reads
parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_Phix_removal.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/HQ_read_singles.list


#parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_PhiX_removal_subset.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/HQ_reads.list

#parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_Phix_removal.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/HQ_reads.list



___________________________________________________________________________

#when running host contamination on gallus gallus and Brachypodium distachyon - related to all relavent corn species - but with a choromosome size below 500 MB. 
# qsub_bbmap_contamination_subset.sh - virker på subsets men qsub_bbmap_contamination.sh virker ikke af uforklarelige årsager, men med parallels udenfor qsub ser det bedre ud. + nodisk=true og -t=32

parallel --xapply "qsub -F '{1} {2}' /home/projects/dtu_00009/data/Scripts/qsub_bbmap_contamination_paired.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/NoPhiX_r1.list :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/NoPhiX_r2.list

parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_bbmap_contamination_singles.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/NoPhiX_singles.list

___________________________________________________________________________


### nonpareil
#make a list of all the preprocessed reads

ls /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/No_contamination | grep '_1.fastq.gz$' > /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/preprocessed_r1.list

#unziping the files in No_contamination folder. 

#on a small test list
parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_unzip_nonpareil.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/test.list

parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_unzip_nonpareil.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/preprocessed_r1.list

# creating a new list with the unzipped file names - so without .gz in the end. 
ls /home/projects/dtu_00009/data/chicken_data_TM/2_omgangNo_contamination | grep '_1.fastq$' > /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/preprocessed_r1_unzipped.list


# running the nonpareil
parallel " qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_nonpareil.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/preprocessed_r1_unzipped.list

# for the test list:
parallel " qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_nonpareil.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/unzipped_test.list



# rezipping the files again
#on the test.list
parallel -j 32 "nonpareil -s /home/projects/dtu_00009/data/chicken_data_TM/No_contamination{} -T kmer -b {.} -f fastq -t 32" :::: /home/projects/dtu_00009/data/chicken_data_TM/unzipped_test.list

# rezip on the full list
parallel -j 32 "nonpareil -s /home/projects/dtu_00009/data/chicken_data_TM/No_contamination{} -T kmer -b {.} -f fastq -t 32" :::: /home/projects/dtu_00009/data/chicken_data_TM/preprocessed_r1_unzipped.list

parallel "qsub -F '{1}' /home/projects/dtu_00009/data/Scripts/qsub_rezip_after_nonpareil.sh" :::: /home/projects/dtu_00009/data/chicken_data_TM/2_omgang/preprocessed_r1_unzipped.list


___________________________________________________________________________

## Assembley

#for counting kmers. (not sure why) -m 15 is kmer size of 15. 
gzip -dc Vchol-001_6.pair*.truncated.gz | jellyfish count -t 2 -m 15 -s 1000000000 -o Vchol-001 -C /dev/fd/0
jellyfish histo Vchol-001 > Vchol-001.histo

R
dat=read.table("Vchol-001.histo")
barplot(dat[,2], xlim=c(0,150), ylim=c(0,5e5), ylab="No of kmers", xlab="Counts of a k-mer", names.arg=dat[,1], cex.names=0.8)
dev.print("Vchol-001.histo.pdf", device=pdf)

# to view the plot or download if it dosen't work - or download anyway to keep: 
evince kmerFreq.pdf &

#running SPAdes - SPAdes will run error correction and use multiple k-mers at the same time when it is doing the assembly. 

/home/27626/bin/spades.py --meta -1 MH0047.1.fastq.gz -2 MH0047.2.fastq.gz -m 120 -o spades_MH0047

# some SPAdes options 
-t <int> (or --threads <int>) :Number of threads. The default value is 16.

-m <int> (or --memory <int>) Set memory limit in Gb. SPAdes terminates if it reaches this limit. The default value is 250 Gb. Actual amount of consumed RAM will be below this limit. Make sure this value is correct for the given machine. SPAdes uses the limit value to automatically determine the sizes of various buffers, etc.


#Path to SPAdes
home/projects/dtu_00009/people/majjag/Bin/Programs/miniconda3/envs/env_SPAdes/bin/spades.py






